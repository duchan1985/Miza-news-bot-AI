import feedparser, time

# C·∫•u h√¨nh c√°c ngu·ªìn tin c√¥ng khai qua RSSHub ho·∫∑c Google News
SOURCES = [
    {"name": "Google News", "url": "https://news.google.com/rss/search?q=Miza&hl=vi&gl=VN&ceid=VN:vi"},
    {"name": "YouTube", "url": "https://rsshub.app/youtube/search/Miza"},
    {"name": "TikTok", "url": "https://rsshub.app/tiktok/search/Miza"},
    {"name": "Facebook", "url": "https://rsshub.app/facebook/page/MizaPaper"},
    {"name": "Instagram", "url": "https://rsshub.app/instagram/user/miza.vn"},
]

def parse_rss(url):
    """ƒê·ªçc v√† l·ªçc c√°c b√†i c√≥ ch·ªØ 'Miza' trong ti√™u ƒë·ªÅ."""
    feed = feedparser.parse(url)
    results = []
    for e in feed.entries[:10]:
        title, link = e.get("title", ""), e.get("link", "")
        if "miza" in title.lower():
            results.append({"title": title.strip(), "link": link.strip()})
    return results

def fetch_all_sources():
    """L·∫•y tin t·ª´ t·∫•t c·∫£ ngu·ªìn."""
    all_entries = []
    for s in SOURCES:
        print(f"üîç Fetching from {s['name']} ...")
        try:
            items = parse_rss(s["url"])
            all_entries.extend(items)
        except Exception as e:
            print(f"‚ö†Ô∏è Error fetching {s['name']}: {e}")
        time.sleep(1)
    return all_entries
